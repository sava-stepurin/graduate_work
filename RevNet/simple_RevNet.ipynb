{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "simple_RevNet.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTsQzNug-qez",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "keras, L = tf.keras, tf.keras.layers\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from skimage.transform import resize\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VGE2OB-Y-7mM",
        "colab_type": "code",
        "outputId": "e1c29ce2-40d6-48bd-c238-68a0c43745bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 615
        }
      },
      "source": [
        "!pip3 install tensorflow-gpu==2.0.0"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.0.0 in /usr/local/lib/python3.6/dist-packages (2.0.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.1.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.15.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.11.2)\n",
            "Requirement already satisfied: tensorboard<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.1.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (2.0.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.1.8)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.17.5)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.11.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.16.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0.0)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (4.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow-gpu==2.0.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_953Uyg-qe6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KYdanPIT-qe-",
        "colab_type": "code",
        "outputId": "260257ef-4bed-4468-ccf0-21f9a6d6a3b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "for i in range(5):\n",
        "    plt.imshow(np.reshape(X[i], (28, 28)), cmap=plt.cm.gray_r)\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nm1cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/D8K28WFOQm56wAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXaDdg_H-qfE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)\n",
        "del X, y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evK9PsnJ-qfJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.reshape(X_train, (X_train.shape[0], 28, 28))\n",
        "X_train = np.stack([X_train]*3, axis=-1)\n",
        "y_train = y_train.astype(int)\n",
        "\n",
        "X_test = np.reshape(X_test, (X_test.shape[0], 28, 28))\n",
        "X_test = np.stack([X_test]*3, axis=-1)\n",
        "y_test = y_test.astype(int)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LjKDlb0x-qfa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def init_block(x, filters):\n",
        "    x = L.Conv2D(filters=filters, kernel_size=1, \n",
        "                 input_shape=input_shape, padding=\"SAME\")(x)\n",
        "    return x"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OoWXxarE-qfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def f(x, filters):\n",
        "    x = L.BatchNormalization(axis=3)(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "    x = L.Conv2D(filters=filters, kernel_size=3, padding=\"SAME\")(x)\n",
        "    x = L.BatchNormalization(axis=3)(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "    x = L.Conv2D(filters=filters, kernel_size=3, padding=\"SAME\")(x)\n",
        "    \n",
        "    return x\n",
        "\n",
        "def rev_block(x, filters):\n",
        "    x1, x2 = tf.split(x, num_or_size_splits=2, axis=3)\n",
        "    y1 = f(x2, filters // 2) + x1\n",
        "    y2 = f(y1, filters // 2) + x2\n",
        "\n",
        "    return tf.concat([y1, y2], axis=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HcB0-STX-qfi",
        "colab_type": "text"
      },
      "source": [
        "**Модель с Reversible блоком, но в конце которой находятся Dense слои:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EJJms__u-qfj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "filters = 32\n",
        "n_rev_blocks = 1\n",
        "n_classes = 10\n",
        "\n",
        "def build_model():\n",
        "    img_input = L.Input(input_shape)\n",
        "    x = init_block(img_input, filters)\n",
        "    for _ in range(n_rev_blocks):\n",
        "        x = rev_block(x, filters)\n",
        "    x = L.Flatten()(x)\n",
        "\n",
        "    x = L.Dense(100)(x)\n",
        "    x = L.Activation(\"relu\")(x)\n",
        "    x = L.Dense(n_classes)(x)\n",
        "    x = L.Activation(\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(img_input, x)\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G3dac-P-qfn",
        "colab_type": "code",
        "outputId": "f5e8e3c9-f6db-49ac-b6bc-a9393dead695",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 986
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_5 (InputLayer)            [(None, 28, 28, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 28, 28, 32)   128         input_5[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_split_4 (TensorFlow [(None, 28, 28, 16), 0           conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 28, 28, 16)   64          tf_op_layer_split_4[0][1]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 28, 28, 16)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 28, 28, 16)   2320        activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 28, 28, 16)   64          conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 28, 28, 16)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 28, 28, 16)   2320        activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_8 (TensorFlowOp [(None, 28, 28, 16)] 0           conv2d_22[0][0]                  \n",
            "                                                                 tf_op_layer_split_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 28, 28, 16)   64          tf_op_layer_add_8[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 28, 28, 16)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 28, 28, 16)   2320        activation_24[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 28, 28, 16)   64          conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 28, 28, 16)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 28, 28, 16)   2320        activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_9 (TensorFlowOp [(None, 28, 28, 16)] 0           conv2d_24[0][0]                  \n",
            "                                                                 tf_op_layer_split_4[0][1]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_4 (TensorFlo [(None, 28, 28, 32)] 0           tf_op_layer_add_8[0][0]          \n",
            "                                                                 tf_op_layer_add_9[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_4 (Flatten)             (None, 25088)        0           tf_op_layer_concat_4[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "dense_4 (Dense)                 (None, 100)          2508900     flatten_4[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 100)          0           dense_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_5 (Dense)                 (None, 10)           1010        activation_26[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 10)           0           dense_5[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 2,519,574\n",
            "Trainable params: 2,519,446\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sPHZSQn-qfr",
        "colab_type": "code",
        "outputId": "6131bdf4-5de0-41da-8439-8811292d47fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 884
        }
      },
      "source": [
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"revnet_with_dense.hdf5\", \n",
        "                                               verbose=1, save_best_only=True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=40, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/40\n",
            "52416/52500 [============================>.] - ETA: 0s - loss: 2.3425 - sparse_categorical_accuracy: 0.6589\n",
            "Epoch 00001: val_loss improved from inf to 0.88950, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 13s 243us/sample - loss: 2.3401 - sparse_categorical_accuracy: 0.6591 - val_loss: 0.8895 - val_sparse_categorical_accuracy: 0.7757\n",
            "Epoch 2/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.6189 - sparse_categorical_accuracy: 0.8334\n",
            "Epoch 00002: val_loss improved from 0.88950 to 0.40819, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 12s 224us/sample - loss: 0.6184 - sparse_categorical_accuracy: 0.8335 - val_loss: 0.4082 - val_sparse_categorical_accuracy: 0.8925\n",
            "Epoch 3/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: 0.2397 - sparse_categorical_accuracy: 0.9389\n",
            "Epoch 00003: val_loss improved from 0.40819 to 0.16763, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 12s 223us/sample - loss: 0.2397 - sparse_categorical_accuracy: 0.9389 - val_loss: 0.1676 - val_sparse_categorical_accuracy: 0.9574\n",
            "Epoch 4/40\n",
            "52256/52500 [============================>.] - ETA: 0s - loss: 0.1443 - sparse_categorical_accuracy: 0.9615\n",
            "Epoch 00004: val_loss did not improve from 0.16763\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.1441 - sparse_categorical_accuracy: 0.9615 - val_loss: 0.1693 - val_sparse_categorical_accuracy: 0.9531\n",
            "Epoch 5/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 0.1114 - sparse_categorical_accuracy: 0.9698\n",
            "Epoch 00005: val_loss improved from 0.16763 to 0.14574, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.1112 - sparse_categorical_accuracy: 0.9699 - val_loss: 0.1457 - val_sparse_categorical_accuracy: 0.9623\n",
            "Epoch 6/40\n",
            "52384/52500 [============================>.] - ETA: 0s - loss: 0.1078 - sparse_categorical_accuracy: 0.9722\n",
            "Epoch 00006: val_loss improved from 0.14574 to 0.14496, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 12s 226us/sample - loss: 0.1077 - sparse_categorical_accuracy: 0.9723 - val_loss: 0.1450 - val_sparse_categorical_accuracy: 0.9643\n",
            "Epoch 7/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.0891 - sparse_categorical_accuracy: 0.9760\n",
            "Epoch 00007: val_loss improved from 0.14496 to 0.10011, saving model to revnet_with_dense.hdf5\n",
            "52500/52500 [==============================] - 12s 224us/sample - loss: 0.0890 - sparse_categorical_accuracy: 0.9761 - val_loss: 0.1001 - val_sparse_categorical_accuracy: 0.9743\n",
            "Epoch 8/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: 0.0854 - sparse_categorical_accuracy: 0.9780\n",
            "Epoch 00008: val_loss did not improve from 0.10011\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.0855 - sparse_categorical_accuracy: 0.9780 - val_loss: 0.1238 - val_sparse_categorical_accuracy: 0.9692\n",
            "Epoch 9/40\n",
            "52384/52500 [============================>.] - ETA: 0s - loss: 0.0831 - sparse_categorical_accuracy: 0.9794\n",
            "Epoch 00009: val_loss did not improve from 0.10011\n",
            "52500/52500 [==============================] - 12s 221us/sample - loss: 0.0830 - sparse_categorical_accuracy: 0.9794 - val_loss: 0.1599 - val_sparse_categorical_accuracy: 0.9666\n",
            "Epoch 10/40\n",
            "52416/52500 [============================>.] - ETA: 0s - loss: 0.0753 - sparse_categorical_accuracy: 0.9809\n",
            "Epoch 00010: val_loss did not improve from 0.10011\n",
            "52500/52500 [==============================] - 12s 225us/sample - loss: 0.0752 - sparse_categorical_accuracy: 0.9810 - val_loss: 0.2866 - val_sparse_categorical_accuracy: 0.9485\n",
            "Epoch 11/40\n",
            "52320/52500 [============================>.] - ETA: 0s - loss: 0.0703 - sparse_categorical_accuracy: 0.9828\n",
            "Epoch 00011: val_loss did not improve from 0.10011\n",
            "52500/52500 [==============================] - 12s 228us/sample - loss: 0.0702 - sparse_categorical_accuracy: 0.9829 - val_loss: 0.1239 - val_sparse_categorical_accuracy: 0.9779\n",
            "Epoch 12/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: 0.0688 - sparse_categorical_accuracy: 0.9833\n",
            "Epoch 00012: val_loss did not improve from 0.10011\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.0688 - sparse_categorical_accuracy: 0.9833 - val_loss: 0.1616 - val_sparse_categorical_accuracy: 0.9681\n",
            "Epoch 00012: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce386e9b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 212
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KhBjbJ4FHA8A",
        "colab_type": "text"
      },
      "source": [
        "**Переобучение сети на маленьком батче:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjkGca2NF_d9",
        "colab_type": "code",
        "outputId": "b5305ef4-8b81-4241-a759-32312469893a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train[:32], y_train[:32],\n",
        "          batch_size=32, epochs=40,\n",
        "          callbacks=[earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32 samples\n",
            "Epoch 1/40\n",
            "32/32 [==============================] - 1s 32ms/sample - loss: 52.8831 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 0s 441us/sample - loss: 158.0528 - sparse_categorical_accuracy: 0.4688\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 0s 430us/sample - loss: 188.1282 - sparse_categorical_accuracy: 0.5000\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 0s 432us/sample - loss: 128.7907 - sparse_categorical_accuracy: 0.5312\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 0s 352us/sample - loss: 66.2178 - sparse_categorical_accuracy: 0.6562\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 0s 346us/sample - loss: 22.7801 - sparse_categorical_accuracy: 0.7188\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 0s 340us/sample - loss: 5.4840 - sparse_categorical_accuracy: 0.8438\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 0s 383us/sample - loss: 2.0206 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 0s 379us/sample - loss: 1.3962 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 0s 541us/sample - loss: 1.4436 - sparse_categorical_accuracy: 0.8438\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 0s 350us/sample - loss: 0.8561 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 0s 426us/sample - loss: 0.5782 - sparse_categorical_accuracy: 0.9375\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 0s 353us/sample - loss: 0.0329 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 0s 336us/sample - loss: 0.0046 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 0s 368us/sample - loss: 0.4755 - sparse_categorical_accuracy: 0.9688\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 0s 426us/sample - loss: 2.9609e-05 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 0s 567us/sample - loss: 9.3555e-05 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 0s 418us/sample - loss: 1.8279e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 0s 386us/sample - loss: 2.6565e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 0s 440us/sample - loss: 2.6850e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 0s 377us/sample - loss: 5.3148e-04 - sparse_categorical_accuracy: 1.0000\n",
            "Epoch 00021: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce82a3eb38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KeJ51RvQLBs0",
        "colab_type": "text"
      },
      "source": [
        "**LR range test** (https://www.kaggle.com/paultimothymooney/learning-rate-finder-for-keras):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-87see6NNw9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import math\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "import tensorflow.keras.backend as K"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0WhkCGaxHIMT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LRFinder:\n",
        "    \"\"\"\n",
        "    Plots the change of the loss function of a Keras model when the learning rate is exponentially increasing.\n",
        "    See for details:\n",
        "    https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0\n",
        "    \"\"\"\n",
        "    def __init__(self, model):\n",
        "        self.model = model\n",
        "        self.losses = []\n",
        "        self.lrs = []\n",
        "        self.best_loss = 1e9\n",
        "\n",
        "    def on_batch_end(self, batch, logs):\n",
        "        lr = K.get_value(self.model.optimizer.lr)\n",
        "        self.lrs.append(lr)\n",
        "\n",
        "        loss = logs['loss']\n",
        "        self.losses.append(loss)\n",
        "\n",
        "        if math.isnan(loss) or loss > self.best_loss * 1000:\n",
        "            self.model.stop_training = True\n",
        "            return\n",
        "\n",
        "        if loss < self.best_loss:\n",
        "            self.best_loss = loss\n",
        "\n",
        "        lr *= self.lr_mult\n",
        "        K.set_value(self.model.optimizer.lr, lr)\n",
        "\n",
        "    def find(self, x_train, y_train, start_lr, end_lr, batch_size=64, epochs=1):\n",
        "        num_batches = epochs * x_train.shape[0] / batch_size\n",
        "        self.lr_mult = (end_lr / start_lr) ** (1 / num_batches)\n",
        "\n",
        "        self.model.save_weights('tmp.h5')\n",
        "\n",
        "        original_lr = K.get_value(self.model.optimizer.lr)\n",
        "\n",
        "        K.set_value(self.model.optimizer.lr, start_lr)\n",
        "\n",
        "        callback = LambdaCallback(on_batch_end=lambda batch, logs: self.on_batch_end(batch, logs))\n",
        "\n",
        "        self.model.fit(x_train, y_train,\n",
        "                        batch_size=batch_size, epochs=epochs,\n",
        "                        callbacks=[callback])\n",
        "\n",
        "        self.model.load_weights('tmp.h5')\n",
        "\n",
        "        K.set_value(self.model.optimizer.lr, original_lr)\n",
        "\n",
        "    def plot_loss(self, n_skip_beginning=10, n_skip_end=5, y_lim=(0, 100)):\n",
        "        \"\"\"\n",
        "        Plots the loss.\n",
        "        Parameters:\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "        \"\"\"\n",
        "        plt.figure(figsize=(12, 8))\n",
        "        plt.ylabel(\"loss\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        x = self.lrs[n_skip_beginning:-n_skip_end]\n",
        "        y = self.losses[n_skip_beginning:-n_skip_end]\n",
        "        plt.plot(x, y)\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n",
        "\n",
        "    def plot_loss_change(self, sma=1, n_skip_beginning=10, n_skip_end=5, y_lim=(-0.01, 0.01)):\n",
        "        \"\"\"\n",
        "        Plots rate of change of the loss function.\n",
        "        Parameters:\n",
        "            sma - number of batches for simple moving average to smooth out the curve.\n",
        "            n_skip_beginning - number of batches to skip on the left.\n",
        "            n_skip_end - number of batches to skip on the right.\n",
        "            y_lim - limits for the y axis.\n",
        "        \"\"\"\n",
        "        assert sma >= 1\n",
        "        derivatives = [0] * sma\n",
        "        for i in range(sma, len(self.lrs)):\n",
        "            derivative = (self.losses[i] - self.losses[i - sma]) / sma\n",
        "            derivatives.append(derivative)\n",
        "\n",
        "        plt.ylabel(\"rate of loss change\")\n",
        "        plt.xlabel(\"learning rate (log scale)\")\n",
        "        plt.plot(self.lrs[n_skip_beginning:-n_skip_end], derivatives[n_skip_beginning:-n_skip_end])\n",
        "        plt.xscale('log')\n",
        "        plt.ylim(y_lim)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HUI92jIrceqQ",
        "colab_type": "text"
      },
      "source": [
        "Для SGD:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niItIJwaM4Ib",
        "colab_type": "code",
        "outputId": "d013bf03-2355-4643-c5b4-96eff5dd3f47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "lr_finder = LRFinder(model)\n",
        "lr_finder.find(X_train, y_train, start_lr=0.0001, end_lr=100, batch_size=512, epochs=1)\n",
        "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1, y_lim=(0, 25))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples\n",
            "16384/52500 [========>.....................] - ETA: 4s - loss: 252.6918 - sparse_categorical_accuracy: 0.4140"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAHoCAYAAACyxtKZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIoeaItdTZKkAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CLbQFAichBB",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим качество обучения для лучших lr:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yZjQe2XPW69a",
        "colab_type": "code",
        "outputId": "f9478626-2ca8-4d7b-b02b-b4a7c9406ce6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        " model = build_model()\n",
        " \n",
        " model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-4),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"revnet_with_dense_sgd.hdf5\", \n",
        "                                               verbose=1, save_best_only=True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=40, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/40\n",
            "52192/52500 [============================>.] - ETA: 0s - loss: 1.1177 - sparse_categorical_accuracy: 0.7969\n",
            "Epoch 00001: val_loss improved from inf to 0.57685, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 218us/sample - loss: 1.1140 - sparse_categorical_accuracy: 0.7974 - val_loss: 0.5769 - val_sparse_categorical_accuracy: 0.8753\n",
            "Epoch 2/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.4586 - sparse_categorical_accuracy: 0.8939\n",
            "Epoch 00002: val_loss improved from 0.57685 to 0.45376, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 202us/sample - loss: 0.4585 - sparse_categorical_accuracy: 0.8939 - val_loss: 0.4538 - val_sparse_categorical_accuracy: 0.9013\n",
            "Epoch 3/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: 0.3565 - sparse_categorical_accuracy: 0.9154\n",
            "Epoch 00003: val_loss improved from 0.45376 to 0.37887, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 203us/sample - loss: 0.3564 - sparse_categorical_accuracy: 0.9155 - val_loss: 0.3789 - val_sparse_categorical_accuracy: 0.9189\n",
            "Epoch 4/40\n",
            "52352/52500 [============================>.] - ETA: 0s - loss: 0.3050 - sparse_categorical_accuracy: 0.9268\n",
            "Epoch 00004: val_loss improved from 0.37887 to 0.34950, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 201us/sample - loss: 0.3052 - sparse_categorical_accuracy: 0.9268 - val_loss: 0.3495 - val_sparse_categorical_accuracy: 0.9243\n",
            "Epoch 5/40\n",
            "52352/52500 [============================>.] - ETA: 0s - loss: 0.2713 - sparse_categorical_accuracy: 0.9333\n",
            "Epoch 00005: val_loss improved from 0.34950 to 0.34436, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 201us/sample - loss: 0.2714 - sparse_categorical_accuracy: 0.9333 - val_loss: 0.3444 - val_sparse_categorical_accuracy: 0.9250\n",
            "Epoch 6/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.2470 - sparse_categorical_accuracy: 0.9388\n",
            "Epoch 00006: val_loss improved from 0.34436 to 0.32183, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 10s 198us/sample - loss: 0.2470 - sparse_categorical_accuracy: 0.9388 - val_loss: 0.3218 - val_sparse_categorical_accuracy: 0.9303\n",
            "Epoch 7/40\n",
            "52192/52500 [============================>.] - ETA: 0s - loss: 0.2234 - sparse_categorical_accuracy: 0.9427\n",
            "Epoch 00007: val_loss did not improve from 0.32183\n",
            "52500/52500 [==============================] - 11s 200us/sample - loss: 0.2229 - sparse_categorical_accuracy: 0.9428 - val_loss: 0.3328 - val_sparse_categorical_accuracy: 0.9321\n",
            "Epoch 8/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.2052 - sparse_categorical_accuracy: 0.9474\n",
            "Epoch 00008: val_loss improved from 0.32183 to 0.29540, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 200us/sample - loss: 0.2054 - sparse_categorical_accuracy: 0.9473 - val_loss: 0.2954 - val_sparse_categorical_accuracy: 0.9339\n",
            "Epoch 9/40\n",
            "52352/52500 [============================>.] - ETA: 0s - loss: 0.1897 - sparse_categorical_accuracy: 0.9508\n",
            "Epoch 00009: val_loss did not improve from 0.29540\n",
            "52500/52500 [==============================] - 10s 198us/sample - loss: 0.1897 - sparse_categorical_accuracy: 0.9509 - val_loss: 0.3037 - val_sparse_categorical_accuracy: 0.9349\n",
            "Epoch 10/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.1749 - sparse_categorical_accuracy: 0.9542\n",
            "Epoch 00010: val_loss improved from 0.29540 to 0.28950, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 201us/sample - loss: 0.1750 - sparse_categorical_accuracy: 0.9542 - val_loss: 0.2895 - val_sparse_categorical_accuracy: 0.9375\n",
            "Epoch 11/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.1636 - sparse_categorical_accuracy: 0.9568\n",
            "Epoch 00011: val_loss improved from 0.28950 to 0.27898, saving model to revnet_with_dense_sgd.hdf5\n",
            "52500/52500 [==============================] - 11s 202us/sample - loss: 0.1638 - sparse_categorical_accuracy: 0.9567 - val_loss: 0.2790 - val_sparse_categorical_accuracy: 0.9399\n",
            "Epoch 12/40\n",
            "52192/52500 [============================>.] - ETA: 0s - loss: 0.1513 - sparse_categorical_accuracy: 0.9599\n",
            "Epoch 00012: val_loss did not improve from 0.27898\n",
            "52500/52500 [==============================] - 10s 199us/sample - loss: 0.1513 - sparse_categorical_accuracy: 0.9598 - val_loss: 0.2848 - val_sparse_categorical_accuracy: 0.9402\n",
            "Epoch 13/40\n",
            "52256/52500 [============================>.] - ETA: 0s - loss: 0.1431 - sparse_categorical_accuracy: 0.9614\n",
            "Epoch 00013: val_loss did not improve from 0.27898\n",
            "52500/52500 [==============================] - 10s 199us/sample - loss: 0.1429 - sparse_categorical_accuracy: 0.9614 - val_loss: 0.2867 - val_sparse_categorical_accuracy: 0.9393\n",
            "Epoch 14/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.1347 - sparse_categorical_accuracy: 0.9630\n",
            "Epoch 00014: val_loss did not improve from 0.27898\n",
            "52500/52500 [==============================] - 10s 199us/sample - loss: 0.1346 - sparse_categorical_accuracy: 0.9630 - val_loss: 0.2832 - val_sparse_categorical_accuracy: 0.9430\n",
            "Epoch 15/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 0.1275 - sparse_categorical_accuracy: 0.9648\n",
            "Epoch 00015: val_loss did not improve from 0.27898\n",
            "52500/52500 [==============================] - 10s 198us/sample - loss: 0.1272 - sparse_categorical_accuracy: 0.9648 - val_loss: 0.2822 - val_sparse_categorical_accuracy: 0.9404\n",
            "Epoch 16/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 0.1208 - sparse_categorical_accuracy: 0.9664\n",
            "Epoch 00016: val_loss did not improve from 0.27898\n",
            "52500/52500 [==============================] - 10s 197us/sample - loss: 0.1206 - sparse_categorical_accuracy: 0.9664 - val_loss: 0.2826 - val_sparse_categorical_accuracy: 0.9436\n",
            "Epoch 00016: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce787c9080>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 201
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yQPIcBGPcHfo",
        "colab_type": "code",
        "outputId": "d8ee1c54-2d20-4029-b344-5f9ecdbb6dd0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        " model = build_model()\n",
        " \n",
        " model.compile(optimizer=keras.optimizers.SGD(learning_rate=1e-3),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"revnet_with_dense_sgd.hdf5\", \n",
        "                                               verbose=1, save_best_only=True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=40, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: nan - sparse_categorical_accuracy: 0.0988\n",
            "Epoch 00001: val_loss did not improve from inf\n",
            "52500/52500 [==============================] - 12s 231us/sample - loss: nan - sparse_categorical_accuracy: 0.0988 - val_loss: nan - val_sparse_categorical_accuracy: 0.0979\n",
            "Epoch 2/40\n",
            "16192/52500 [========>.....................] - ETA: 6s - loss: nan - sparse_categorical_accuracy: 0.0980WARNING:tensorflow:Can save best model only with val_loss available, skipping.\n",
            "WARNING:tensorflow:Early stopping conditioned on metric `val_loss` which is not available. Available metrics are: loss,sparse_categorical_accuracy\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-204-90d81d4c492e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m          \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m40\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m          \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m          callbacks=[checkpointer, earlystopper])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[1;32m    122\u001b[0m       \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m       \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[0;34m(input_fn)\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[0;32m---> 86\u001b[0;31m                               distributed_function(input_fn))\n\u001b[0m\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 535\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    537\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2_utils.py\u001b[0m in \u001b[0;36m_non_none_constant_value\u001b[0;34m(v)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_non_none_constant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m   \u001b[0mconstant_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensor_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstant_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstant_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/tensor_util.py\u001b[0m in \u001b[0;36mconstant_value\u001b[0;34m(tensor, partial)\u001b[0m\n\u001b[1;32m    790\u001b[0m   \"\"\"\n\u001b[1;32m    791\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEagerTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m       \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtype\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mrepresentable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m     \"\"\"\n\u001b[0;32m--> 933\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXpG7g78cnQT",
        "colab_type": "text"
      },
      "source": [
        "В последнем случае SGD функция потерь сразу ушла в nan"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTOHaG3HcujO",
        "colab_type": "text"
      },
      "source": [
        "Посмотрим то же самое для Adam:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJMfd48GYbml",
        "colab_type": "code",
        "outputId": "5593b2c6-fbb8-43cd-837b-85f819d579f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "lr_finder = LRFinder(model)\n",
        "lr_finder.find(X_train, y_train, start_lr=0.0001, end_lr=100, batch_size=512, epochs=1)\n",
        "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1, y_lim=(0, 25))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples\n",
            "34816/52500 [==================>...........] - ETA: 1s - loss: 16.5278 - sparse_categorical_accuracy: 0.5558"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAHoCAYAAACyxtKZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiIiAahoFhEREREJQEWziIiIiEgA/weam0oTop3oUAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5PoX9LtYko1",
        "colab_type": "code",
        "outputId": "c027562d-6687-4eb2-f9b1-6a5e876686d6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 476
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate=1e-2)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"revnet_with_dense_lr.hdf5\", \n",
        "                                               verbose=1, save_best_only=True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=40, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/40\n",
            "52480/52500 [============================>.] - ETA: 0s - loss: 9.8800 - sparse_categorical_accuracy: 0.4767\n",
            "Epoch 00001: val_loss improved from inf to 1.23393, saving model to revnet_with_dense_lr.hdf5\n",
            "52500/52500 [==============================] - 12s 238us/sample - loss: 9.8766 - sparse_categorical_accuracy: 0.4767 - val_loss: 1.2339 - val_sparse_categorical_accuracy: 0.6214\n",
            "Epoch 2/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 1.7716 - sparse_categorical_accuracy: 0.3961\n",
            "Epoch 00002: val_loss did not improve from 1.23393\n",
            "52500/52500 [==============================] - 11s 218us/sample - loss: 1.7735 - sparse_categorical_accuracy: 0.3956 - val_loss: 2.0485 - val_sparse_categorical_accuracy: 0.2289\n",
            "Epoch 3/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 2.2555 - sparse_categorical_accuracy: 0.1552\n",
            "Epoch 00003: val_loss did not improve from 1.23393\n",
            "52500/52500 [==============================] - 11s 216us/sample - loss: 2.2557 - sparse_categorical_accuracy: 0.1550 - val_loss: 2.3018 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 4/40\n",
            "52320/52500 [============================>.] - ETA: 0s - loss: 2.3058 - sparse_categorical_accuracy: 0.1100\n",
            "Epoch 00004: val_loss did not improve from 1.23393\n",
            "52500/52500 [==============================] - 11s 215us/sample - loss: 2.3058 - sparse_categorical_accuracy: 0.1099 - val_loss: 2.3036 - val_sparse_categorical_accuracy: 0.1034\n",
            "Epoch 5/40\n",
            "52416/52500 [============================>.] - ETA: 0s - loss: 2.3029 - sparse_categorical_accuracy: 0.1097\n",
            "Epoch 00005: val_loss did not improve from 1.23393\n",
            "52500/52500 [==============================] - 11s 215us/sample - loss: 2.3029 - sparse_categorical_accuracy: 0.1096 - val_loss: 2.3023 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 6/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 2.3028 - sparse_categorical_accuracy: 0.1089\n",
            "Epoch 00006: val_loss did not improve from 1.23393\n",
            "52500/52500 [==============================] - 11s 216us/sample - loss: 2.3028 - sparse_categorical_accuracy: 0.1090 - val_loss: 2.3023 - val_sparse_categorical_accuracy: 0.1130\n",
            "Epoch 00006: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce350bdc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 190
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQ9udU6wadH9",
        "colab_type": "code",
        "outputId": "88a8e694-ec2b-49fb-c6ae-6b88946af612",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 816
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate=1e-3)\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "checkpointer = keras.callbacks.ModelCheckpoint(filepath=\"revnet_with_dense_lr.hdf5\", \n",
        "                                               verbose=1, save_best_only=True)\n",
        "earlystopper = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, \n",
        "                                             verbose=1)\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=40, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[checkpointer, earlystopper])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/40\n",
            "52288/52500 [============================>.] - ETA: 0s - loss: 2.7939 - sparse_categorical_accuracy: 0.4979\n",
            "Epoch 00001: val_loss improved from inf to 1.18438, saving model to revnet_with_dense_lr.hdf5\n",
            "52500/52500 [==============================] - 13s 251us/sample - loss: 2.7865 - sparse_categorical_accuracy: 0.4986 - val_loss: 1.1844 - val_sparse_categorical_accuracy: 0.6418\n",
            "Epoch 2/40\n",
            "52416/52500 [============================>.] - ETA: 0s - loss: 0.9230 - sparse_categorical_accuracy: 0.7089\n",
            "Epoch 00002: val_loss improved from 1.18438 to 0.65049, saving model to revnet_with_dense_lr.hdf5\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.9231 - sparse_categorical_accuracy: 0.7090 - val_loss: 0.6505 - val_sparse_categorical_accuracy: 0.7808\n",
            "Epoch 3/40\n",
            "52256/52500 [============================>.] - ETA: 0s - loss: 0.4861 - sparse_categorical_accuracy: 0.8548\n",
            "Epoch 00003: val_loss improved from 0.65049 to 0.30353, saving model to revnet_with_dense_lr.hdf5\n",
            "52500/52500 [==============================] - 12s 221us/sample - loss: 0.4860 - sparse_categorical_accuracy: 0.8552 - val_loss: 0.3035 - val_sparse_categorical_accuracy: 0.9257\n",
            "Epoch 4/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.2068 - sparse_categorical_accuracy: 0.9451\n",
            "Epoch 00004: val_loss did not improve from 0.30353\n",
            "52500/52500 [==============================] - 12s 220us/sample - loss: 0.2067 - sparse_categorical_accuracy: 0.9451 - val_loss: 0.5021 - val_sparse_categorical_accuracy: 0.8915\n",
            "Epoch 5/40\n",
            "52448/52500 [============================>.] - ETA: 0s - loss: 0.1503 - sparse_categorical_accuracy: 0.9595\n",
            "Epoch 00005: val_loss did not improve from 0.30353\n",
            "52500/52500 [==============================] - 12s 220us/sample - loss: 0.1503 - sparse_categorical_accuracy: 0.9595 - val_loss: 0.3837 - val_sparse_categorical_accuracy: 0.9026\n",
            "Epoch 6/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.1232 - sparse_categorical_accuracy: 0.9666\n",
            "Epoch 00006: val_loss improved from 0.30353 to 0.15186, saving model to revnet_with_dense_lr.hdf5\n",
            "52500/52500 [==============================] - 12s 220us/sample - loss: 0.1235 - sparse_categorical_accuracy: 0.9666 - val_loss: 0.1519 - val_sparse_categorical_accuracy: 0.9615\n",
            "Epoch 7/40\n",
            "52224/52500 [============================>.] - ETA: 0s - loss: 0.1195 - sparse_categorical_accuracy: 0.9683\n",
            "Epoch 00007: val_loss did not improve from 0.15186\n",
            "52500/52500 [==============================] - 12s 219us/sample - loss: 0.1198 - sparse_categorical_accuracy: 0.9682 - val_loss: 0.1818 - val_sparse_categorical_accuracy: 0.9511\n",
            "Epoch 8/40\n",
            "52384/52500 [============================>.] - ETA: 0s - loss: 0.1111 - sparse_categorical_accuracy: 0.9713\n",
            "Epoch 00008: val_loss did not improve from 0.15186\n",
            "52500/52500 [==============================] - 12s 221us/sample - loss: 0.1110 - sparse_categorical_accuracy: 0.9713 - val_loss: 0.8102 - val_sparse_categorical_accuracy: 0.8774\n",
            "Epoch 9/40\n",
            "52256/52500 [============================>.] - ETA: 0s - loss: 0.0936 - sparse_categorical_accuracy: 0.9743\n",
            "Epoch 00009: val_loss did not improve from 0.15186\n",
            "52500/52500 [==============================] - 12s 225us/sample - loss: 0.0937 - sparse_categorical_accuracy: 0.9744 - val_loss: 0.1918 - val_sparse_categorical_accuracy: 0.9578\n",
            "Epoch 10/40\n",
            "52416/52500 [============================>.] - ETA: 0s - loss: 0.0928 - sparse_categorical_accuracy: 0.9755\n",
            "Epoch 00010: val_loss did not improve from 0.15186\n",
            "52500/52500 [==============================] - 12s 222us/sample - loss: 0.0927 - sparse_categorical_accuracy: 0.9755 - val_loss: 0.7265 - val_sparse_categorical_accuracy: 0.8428\n",
            "Epoch 11/40\n",
            "52320/52500 [============================>.] - ETA: 0s - loss: 0.0746 - sparse_categorical_accuracy: 0.9802\n",
            "Epoch 00011: val_loss did not improve from 0.15186\n",
            "52500/52500 [==============================] - 12s 220us/sample - loss: 0.0752 - sparse_categorical_accuracy: 0.9801 - val_loss: 0.1966 - val_sparse_categorical_accuracy: 0.9609\n",
            "Epoch 00011: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce39c58470>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLBpMVevczQO",
        "colab_type": "text"
      },
      "source": [
        "Лучше себя показало значение по умолчанию равное 0.001"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S6CI9tU3gS5P",
        "colab_type": "text"
      },
      "source": [
        "**Среднее, дисперсия и максимальное значение выходов каждого слоя** (https://stackoverflow.com/questions/41711190/keras-how-to-get-the-output-of-each-layer):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dl_vfA1bgYPo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def count_output_stats(model, data):\n",
        "    inp = model.input                                         \n",
        "    outputs = [layer.output for layer in model.layers]\n",
        "    functors = [K.function([inp], [out]) for out in outputs]   \n",
        "\n",
        "    layer_outs = np.array([func(data)[0] for func in functors])\n",
        "\n",
        "    print(\"Layer_name     Mean      Std     AbsMax\")\n",
        "    for out, layer in zip(layer_outs, model.layers):\n",
        "        print(layer.name, np.mean(out), np.std(out), np.max(np.abs(out)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "98xYyqdDg3iE",
        "colab_type": "code",
        "outputId": "886f4a39-8d45-4d93-b709-8178b96cf60e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        }
      },
      "source": [
        "model = keras.models.load_model('revnet_with_dense.hdf5')\n",
        "count_output_stats(model, X_train[:32])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer_name     Mean      Std     AbsMax\n",
            "input_26 33.669403 78.76575 255.0\n",
            "conv2d_125 0.34469685 3.6137059 25.740976\n",
            "tf_op_layer_split_25 0.34469682 3.6137064 25.740976\n",
            "batch_normalization_100 -0.040776733 1.0181673 3.634192\n",
            "activation_147 0.3284836 0.7104299 3.634192\n",
            "conv2d_126 -0.20385407 3.2157915 20.416842\n",
            "batch_normalization_101 -0.18014385 1.0640172 5.8735495\n",
            "activation_148 0.23189177 0.664201 5.593438\n",
            "conv2d_127 -0.06973644 2.491622 19.98863\n",
            "tf_op_layer_add_50 0.32768622 2.2203338 17.570183\n",
            "batch_normalization_102 -0.147246 0.9671924 8.543778\n",
            "activation_149 0.22942124 0.66501045 8.543778\n",
            "conv2d_128 0.060606577 2.08692 17.628712\n",
            "batch_normalization_103 -0.20750129 1.1196847 8.575382\n",
            "activation_150 0.22977695 0.7793017 8.126232\n",
            "conv2d_129 -0.10059774 3.0193844 30.934013\n",
            "tf_op_layer_add_51 0.19137326 2.74274 25.824512\n",
            "tf_op_layer_concat_25 0.2595297 2.496176 25.824512\n",
            "flatten_25 0.2595297 2.496176 25.824512\n",
            "dense_44 -149.66223 137.3638 826.3128\n",
            "activation_151 3.0253463 26.151455 470.04523\n",
            "dense_45 18.37853 13.165466 72.750946\n",
            "activation_152 0.1 0.2960115 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dj1NBrltOKK3",
        "colab_type": "text"
      },
      "source": [
        "**Grad norms** (https://stackoverflow.com/questions/57759635/get-gradients-with-keras-tensorflow-2-0):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaGQWyfnR9R4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class GradientCallback(tf.keras.callbacks.Callback):\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        loss = self.model.total_loss\n",
        "        optimizer = self.model.optimizer\n",
        "        gradients = optimizer.get_gradients(loss, self.model.trainable_weights)\n",
        "        for t in gradients:\n",
        "            print('Tensor: {}'.format(t.name))\n",
        "            print('{}\\n'.format(t.numpy()[:10]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1dEOkVyusYry",
        "colab_type": "text"
      },
      "source": [
        "Данный код кидает ошибку:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BKnOlHshsSoe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "4283ff5e-e2ab-43c4-fc65-6be0d468af16"
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "gradient_callback = GradientCallback()\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=1, \n",
        "          validation_data=(X_test, y_test),\n",
        "          callbacks=[gradient_callback])"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Tensor: Adam/gradients_39/gradients/conv2d_161/Conv2D_grad/Conv2DBackpropFilter:0\n",
            "    0/52500 [..............................] - ETA: 0s"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-90-32cd0753b8ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m           callbacks=[gradient_callback])\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 324\u001b[0;31m                 total_epochs=epochs)\n\u001b[0m\u001b[1;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[0;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[1;32m    172\u001b[0m             batch_end=step * batch_size + current_batch_size)\n\u001b[1;32m    173\u001b[0m       \u001b[0mcbks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 174\u001b[0;31m       \u001b[0mstep\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[0;34m(self, step, mode, size)\u001b[0m\n\u001b[1;32m    698\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data_exhausted'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m         self.callbacks._call_batch_hook(\n\u001b[0;32m--> 700\u001b[0;31m             mode, 'end', step, batch_logs)\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m       \u001b[0mbatch_hook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 235\u001b[0;31m       \u001b[0mbatch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    236\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delta_ts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt_before_callbacks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    516\u001b[0m     \"\"\"\n\u001b[1;32m    517\u001b[0m     \u001b[0;31m# For backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 518\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-55-9554b4160830>\u001b[0m in \u001b[0;36mon_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgradients\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Tensor: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'{}\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tensor' object has no attribute 'numpy'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPIp9mCtsbu6",
        "colab_type": "text"
      },
      "source": [
        "**Свой training loop** (https://www.tensorflow.org/guide/keras/train_and_evaluate):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7QD5yF6-hPRC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = 32\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1024).batch(batch_size)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hvzvPVQbhRwg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "5aae9ae7-2ad2-4dc7-8c2a-1f8ad0ac103f"
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "optimizer = keras.optimizers.Adam()\n",
        "# Instantiate a loss function.\n",
        "loss_fn = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "train_acc_metric = keras.metrics.SparseCategoricalAccuracy()\n",
        "\n",
        "epochs = 3\n",
        "for epoch in range(epochs):\n",
        "  print('Start of epoch %d' % (epoch,))\n",
        "\n",
        "  # Iterate over the batches of the dataset.\n",
        "  for step, (x_batch_train, y_batch_train) in enumerate(train_dataset):\n",
        "\n",
        "    # Open a GradientTape to record the operations run\n",
        "    # during the forward pass, which enables autodifferentiation.\n",
        "    with tf.GradientTape() as tape:\n",
        "\n",
        "      # Run the forward pass of the layer.\n",
        "      # The operations that the layer applies\n",
        "      # to its inputs are going to be recorded\n",
        "      # on the GradientTape.\n",
        "      logits = model(x_batch_train, training=True)  # Logits for this minibatch\n",
        "\n",
        "      # Compute the loss value for this minibatch.\n",
        "      loss_value = loss_fn(y_batch_train, logits)\n",
        "\n",
        "    # Use the gradient tape to automatically retrieve\n",
        "    # the gradients of the trainable variables with respect to the loss.\n",
        "    grads = tape.gradient(loss_value, model.trainable_weights)\n",
        "\n",
        "    # Run one step of gradient descent by updating\n",
        "    # the value of the variables to minimize the loss.\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n",
        "\n",
        "    # Log every 200 batches.\n",
        "    if step % 200 == 0:\n",
        "        print(logits)\n",
        "        print(y_batch_train)\n",
        "        print(train_acc_metric(y_batch_train, logits))\n",
        "        print([tf.norm(grad).numpy() for grad in grads])\n",
        "        print('Training loss (for one batch) at step %s: %s' % (step, float(loss_value)))\n",
        "        print('Seen so far: %s samples' % ((step + 1) * 64))\n",
        "\n",
        "  train_acc = train_acc_metric.result()\n",
        "  print('Training acc over epoch: %s' % (float(train_acc),))"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Start of epoch 0\n",
            "WARNING:tensorflow:Layer conv2d_191 is casting an input tensor from dtype float64 to the layer's dtype of float32, which is new behavior in TensorFlow 2.  The layer has dtype float32 because it's dtype defaults to floatx.\n",
            "\n",
            "If you intended to run this layer in float32, you can safely ignore this warning. If in doubt, this warning is likely only an issue if you are porting a TensorFlow 1.X model to TensorFlow 2.\n",
            "\n",
            "To change all layers to have dtype float64 by default, call `tf.keras.backend.set_floatx('float64')`. To change just this layer, pass dtype='float64' to the layer constructor. If you are the author of this layer, you can disable autocasting by passing autocast=False to the base Layer constructor.\n",
            "\n",
            "tf.Tensor(\n",
            "[[0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 1.0002707e-06 6.7088198e-36 4.2565485e-15\n",
            "  0.0000000e+00 9.9999905e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 2.9756083e-26 1.5139476e-26 0.0000000e+00 3.6670054e-19\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [6.4650535e-26 2.3626639e-17 5.6370819e-22 1.2625733e-27 1.0000000e+00\n",
            "  0.0000000e+00 1.0716489e-15 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [7.3712614e-23 1.8215855e-25 9.8305658e-21 8.9329418e-17 5.4953741e-08\n",
            "  6.0525006e-24 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.0624882e-20]\n",
            " [0.0000000e+00 2.7644319e-33 5.6355353e-04 3.5887173e-18 5.5754013e-02\n",
            "  2.6804283e-36 9.4368237e-01 0.0000000e+00 4.0526140e-32 0.0000000e+00]\n",
            " [1.0456518e-28 2.2533155e-26 2.4838734e-10 0.0000000e+00 6.0918111e-08\n",
            "  0.0000000e+00 9.9999988e-01 0.0000000e+00 0.0000000e+00 1.7276265e-16]\n",
            " [0.0000000e+00 0.0000000e+00 7.5343246e-32 5.9195249e-36 7.4284136e-18\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 7.4575365e-35]\n",
            " [3.7593583e-12 1.8031342e-04 9.9980110e-01 2.2685747e-16 1.8361545e-05\n",
            "  3.7961941e-30 1.9537748e-07 2.4551858e-26 2.9053081e-22 1.9616034e-31]\n",
            " [0.0000000e+00 3.8132529e-21 3.7113795e-33 0.0000000e+00 3.5560515e-21\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.4826787e-33]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.3503658e-35\n",
            "  0.0000000e+00 1.0000000e+00 3.6362689e-38 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 3.7800752e-12 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.6834527e-34]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.2412107e-05\n",
            "  0.0000000e+00 9.9997759e-01 0.0000000e+00 0.0000000e+00 2.8223993e-36]\n",
            " [0.0000000e+00 0.0000000e+00 1.5448382e-34 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [4.6839746e-38 2.3158194e-15 2.3702422e-28 0.0000000e+00 9.5751759e-08\n",
            "  0.0000000e+00 9.9999988e-01 1.7171359e-21 5.4475660e-27 0.0000000e+00]\n",
            " [2.2200959e-22 1.2768926e-32 7.2055088e-30 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.3005429e-30]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.3461981e-13 1.1116115e-22 7.1642659e-18 0.0000000e+00 4.6180170e-03\n",
            "  0.0000000e+00 9.9538201e-01 1.7562589e-21 8.2167463e-20 0.0000000e+00]\n",
            " [0.0000000e+00 3.9903037e-26 2.2223317e-38 0.0000000e+00 4.4080370e-14\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 5.0733717e-20]\n",
            " [2.1969882e-28 1.1432875e-36 1.3941095e-23 0.0000000e+00 6.0196676e-08\n",
            "  0.0000000e+00 9.9999988e-01 2.0477942e-36 3.2845326e-37 0.0000000e+00]\n",
            " [2.9395454e-22 4.4120375e-23 2.4602186e-36 0.0000000e+00 1.5737050e-25\n",
            "  6.8423952e-22 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.4264596e-12]\n",
            " [0.0000000e+00 3.1670830e-33 4.2137231e-07 0.0000000e+00 1.8404728e-16\n",
            "  0.0000000e+00 9.9999952e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
            "  0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [7.0416383e-21 9.9998927e-01 0.0000000e+00 0.0000000e+00 6.8185627e-06\n",
            "  0.0000000e+00 3.9496549e-06 1.0623609e-31 2.7352971e-18 3.0192421e-19]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 2.2967674e-34]\n",
            " [0.0000000e+00 0.0000000e+00 3.8883608e-35 0.0000000e+00 1.0000000e+00\n",
            "  0.0000000e+00 4.1830789e-26 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.0112850e-32\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0911789e-35 4.5479632e-14\n",
            "  0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 4.3486585e-38]\n",
            " [0.0000000e+00 0.0000000e+00 0.0000000e+00 4.2511684e-36 1.0000000e+00\n",
            "  0.0000000e+00 2.8680055e-20 0.0000000e+00 0.0000000e+00 0.0000000e+00]\n",
            " [2.4696938e-23 5.0328367e-26 5.4173323e-04 4.1752633e-20 2.8077741e-08\n",
            "  0.0000000e+00 9.9945825e-01 4.7009000e-19 2.0540346e-31 1.1106700e-18]], shape=(32, 10), dtype=float32)\n",
            "tf.Tensor([4 5 4 3 9 3 4 8 0 4 0 4 7 9 7 4 1 2 2 1 7 1 2 6 0 8 2 3 8 4 3 1], shape=(32,), dtype=int64)\n",
            "tf.Tensor(0.03125, shape=(), dtype=float32)\n",
            "[0.081622936, 0.00047267502, 0.0002488517, 0.0001376378, 0.003949121, 2.303146e-10, 0.00028391797, 0.00028398997, 0.003458082, 0.00034699816, 0.0001399847, 0.000115477975, 0.0032244266, 1.0413615e-10, 0.0001751081, 0.00027046158, 0.0025780916, 0.00032095832, 2.065657, 0.00033085822, 0.12043433, 0.00033548393]\n",
            "Training loss (for one batch) at step 0: 2.4296319484710693\n",
            "Seen so far: 64 samples\n",
            "tf.Tensor(\n",
            "[[0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]], shape=(32, 10), dtype=float32)\n",
            "tf.Tensor([5 9 0 8 5 4 8 0 6 3 1 0 1 3 0 8 6 6 5 2 9 6 2 6 1 5 7 8 2 5 9 8], shape=(32,), dtype=int64)\n",
            "tf.Tensor(0.03125, shape=(), dtype=float32)\n",
            "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
            "Training loss (for one batch) at step 200: 2.4299001693725586\n",
            "Seen so far: 12864 samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-e865cb9df944>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m       \u001b[0;31m# to its inputs are going to be recorded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m       \u001b[0;31m# on the GradientTape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m       \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Logits for this minibatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m       \u001b[0;31m# Compute the loss value for this minibatch.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs, training, mask)\u001b[0m\n\u001b[1;32m    706\u001b[0m     return self._run_internal_graph(\n\u001b[1;32m    707\u001b[0m         \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 708\u001b[0;31m         convert_kwargs_to_constants=base_layer_utils.call_context().saving)\n\u001b[0m\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    710\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcompute_output_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_run_internal_graph\u001b[0;34m(self, inputs, training, mask, convert_kwargs_to_constants)\u001b[0m\n\u001b[1;32m    858\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    859\u001b[0m           \u001b[0;31m# Compute outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 860\u001b[0;31m           \u001b[0moutput_tensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcomputed_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0;31m# Update tensor_dict.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    889\u001b[0m           with base_layer_utils.autocast_context_manager(\n\u001b[1;32m    890\u001b[0m               self._compute_dtype):\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_mask_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2481\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2482\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2483\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_defun_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2484\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1821\u001b[0m     \u001b[0;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1823\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1824\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1825\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1141\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1143\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1222\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[0;32m-> 1224\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1225\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"executor_type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"config_proto\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    512\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[1;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m                                                num_outputs)\n\u001b[0m\u001b[1;32m     62\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBh1drjashk3",
        "colab_type": "text"
      },
      "source": [
        "Непонятно почему вырождается в константную модель, хотя вроде с теми же оптимизаторами и функциями потерь обычный fit работает нормально:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "atYliHWGSVTN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "604ddcfe-b514-4dce-c2a3-661fdc206484"
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=1, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "52500/52500 [==============================] - 13s 255us/sample - loss: 2.5533 - sparse_categorical_accuracy: 0.7498 - val_loss: 0.6652 - val_sparse_categorical_accuracy: 0.8377\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fcbaccddc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cYeZxwFF-qfz",
        "colab_type": "text"
      },
      "source": [
        "**Модель с Reversible блоком, где в конце выбирается 10 чисел из равномерной сетки:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u-g4seN-qf1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "filters = 32\n",
        "n_rev_blocks = 1\n",
        "n_classes = 10\n",
        "\n",
        "def build_model():\n",
        "    img_input = L.Input(input_shape)\n",
        "    x = init_block(img_input, filters)\n",
        "    for _ in range(n_rev_blocks):\n",
        "        x = rev_block(x, filters)\n",
        "    x = L.Flatten()(x)\n",
        "\n",
        "    positions = tf.range(0, x.shape[-1], x.shape[-1] // n_classes + 1)\n",
        "    x = tf.reshape(tf.convert_to_tensor([x[:, i] for i in positions]), (-1, n_classes))\n",
        "    x = L.Activation(\"softmax\")(x)\n",
        "\n",
        "    model = keras.Model(img_input, x)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiV71J6G-qf5",
        "colab_type": "code",
        "outputId": "b0b16e7e-aeca-48f6-cb63-4c5e1f4aebbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_3\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_4 (InputLayer)            [(None, 28, 28, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 28, 28, 32)   128         input_4[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_split_3 (TensorFlow [(None, 28, 28, 16), 0           conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 28, 28, 16)   64          tf_op_layer_split_3[0][1]        \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 28, 28, 16)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 28, 28, 16)   2320        activation_17[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 28, 28, 16)   64          conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 28, 28, 16)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 28, 28, 16)   2320        activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_6 (TensorFlowOp [(None, 28, 28, 16)] 0           conv2d_17[0][0]                  \n",
            "                                                                 tf_op_layer_split_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 28, 28, 16)   64          tf_op_layer_add_6[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 28, 28, 16)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 28, 28, 16)   2320        activation_19[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 28, 28, 16)   64          conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 28, 28, 16)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 28, 28, 16)   2320        activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_add_7 (TensorFlowOp [(None, 28, 28, 16)] 0           conv2d_19[0][0]                  \n",
            "                                                                 tf_op_layer_split_3[0][1]        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_concat_3 (TensorFlo [(None, 28, 28, 32)] 0           tf_op_layer_add_6[0][0]          \n",
            "                                                                 tf_op_layer_add_7[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "flatten_3 (Flatten)             (None, 25088)        0           tf_op_layer_concat_3[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_10 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_11 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_12 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_13 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_14 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_15 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_16 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_17 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_18 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_19 (T [(None,)]            0           flatten_3[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_packed_1 (TensorFlo [(10, None)]         0           tf_op_layer_strided_slice_10[0][0\n",
            "                                                                 tf_op_layer_strided_slice_11[0][0\n",
            "                                                                 tf_op_layer_strided_slice_12[0][0\n",
            "                                                                 tf_op_layer_strided_slice_13[0][0\n",
            "                                                                 tf_op_layer_strided_slice_14[0][0\n",
            "                                                                 tf_op_layer_strided_slice_15[0][0\n",
            "                                                                 tf_op_layer_strided_slice_16[0][0\n",
            "                                                                 tf_op_layer_strided_slice_17[0][0\n",
            "                                                                 tf_op_layer_strided_slice_18[0][0\n",
            "                                                                 tf_op_layer_strided_slice_19[0][0\n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Reshape_1 (TensorFl [(None, 10)]         0           tf_op_layer_packed_1[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 10)           0           tf_op_layer_Reshape_1[0][0]      \n",
            "==================================================================================================\n",
            "Total params: 9,664\n",
            "Trainable params: 9,536\n",
            "Non-trainable params: 128\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wnEnlSFkHQMk",
        "colab_type": "text"
      },
      "source": [
        "**Переобучение модели на маленьком батче:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97YibSkyHPNV",
        "colab_type": "code",
        "outputId": "ff35f40a-94b0-4f53-981c-f62bd1b4f8e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train[:32], y_train[:32],\n",
        "          batch_size=32, epochs=40,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 32 samples\n",
            "Epoch 1/40\n",
            "32/32 [==============================] - 1s 31ms/sample - loss: 36.3624 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 2/40\n",
            "32/32 [==============================] - 0s 402us/sample - loss: 35.5335 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 3/40\n",
            "32/32 [==============================] - 0s 351us/sample - loss: 34.6310 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 4/40\n",
            "32/32 [==============================] - 0s 382us/sample - loss: 30.1114 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 5/40\n",
            "32/32 [==============================] - 0s 356us/sample - loss: 26.2750 - sparse_categorical_accuracy: 0.2812\n",
            "Epoch 6/40\n",
            "32/32 [==============================] - 0s 346us/sample - loss: 26.6770 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 7/40\n",
            "32/32 [==============================] - 0s 326us/sample - loss: 15.6507 - sparse_categorical_accuracy: 0.0312\n",
            "Epoch 8/40\n",
            "32/32 [==============================] - 0s 313us/sample - loss: 29.8816 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 9/40\n",
            "32/32 [==============================] - 0s 334us/sample - loss: 31.9333 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 10/40\n",
            "32/32 [==============================] - 0s 319us/sample - loss: 35.9115 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 11/40\n",
            "32/32 [==============================] - 0s 321us/sample - loss: 33.0287 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 12/40\n",
            "32/32 [==============================] - 0s 329us/sample - loss: 28.0229 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 13/40\n",
            "32/32 [==============================] - 0s 330us/sample - loss: 24.3684 - sparse_categorical_accuracy: 0.1875\n",
            "Epoch 14/40\n",
            "32/32 [==============================] - 0s 334us/sample - loss: 31.0868 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 15/40\n",
            "32/32 [==============================] - 0s 337us/sample - loss: 32.0386 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 16/40\n",
            "32/32 [==============================] - 0s 327us/sample - loss: 23.8688 - sparse_categorical_accuracy: 0.0312\n",
            "Epoch 17/40\n",
            "32/32 [==============================] - 0s 321us/sample - loss: 28.4911 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 18/40\n",
            "32/32 [==============================] - 0s 386us/sample - loss: 22.9465 - sparse_categorical_accuracy: 0.1875\n",
            "Epoch 19/40\n",
            "32/32 [==============================] - 0s 382us/sample - loss: 22.3587 - sparse_categorical_accuracy: 0.0312\n",
            "Epoch 20/40\n",
            "32/32 [==============================] - 0s 335us/sample - loss: 24.7694 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 21/40\n",
            "32/32 [==============================] - 0s 364us/sample - loss: 27.7988 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 22/40\n",
            "32/32 [==============================] - 0s 304us/sample - loss: 29.9139 - sparse_categorical_accuracy: 0.1875\n",
            "Epoch 23/40\n",
            "32/32 [==============================] - 0s 447us/sample - loss: 28.3415 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 24/40\n",
            "32/32 [==============================] - 0s 326us/sample - loss: 19.5183 - sparse_categorical_accuracy: 0.1875\n",
            "Epoch 25/40\n",
            "32/32 [==============================] - 0s 330us/sample - loss: 20.7937 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 26/40\n",
            "32/32 [==============================] - 0s 322us/sample - loss: 27.2161 - sparse_categorical_accuracy: 0.2188\n",
            "Epoch 27/40\n",
            "32/32 [==============================] - 0s 338us/sample - loss: 21.6700 - sparse_categorical_accuracy: 0.2188\n",
            "Epoch 28/40\n",
            "32/32 [==============================] - 0s 319us/sample - loss: 25.5172 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 29/40\n",
            "32/32 [==============================] - 0s 458us/sample - loss: 20.1128 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 30/40\n",
            "32/32 [==============================] - 0s 399us/sample - loss: 27.1565 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 31/40\n",
            "32/32 [==============================] - 0s 330us/sample - loss: 13.8644 - sparse_categorical_accuracy: 0.1875\n",
            "Epoch 32/40\n",
            "32/32 [==============================] - 0s 450us/sample - loss: 26.6512 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 33/40\n",
            "32/32 [==============================] - 0s 286us/sample - loss: 28.5575 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 34/40\n",
            "32/32 [==============================] - 0s 332us/sample - loss: 30.7326 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 35/40\n",
            "32/32 [==============================] - 0s 408us/sample - loss: 25.4578 - sparse_categorical_accuracy: 0.1250\n",
            "Epoch 36/40\n",
            "32/32 [==============================] - 0s 363us/sample - loss: 25.8320 - sparse_categorical_accuracy: 0.0938\n",
            "Epoch 37/40\n",
            "32/32 [==============================] - 0s 349us/sample - loss: 26.1696 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 38/40\n",
            "32/32 [==============================] - 0s 371us/sample - loss: 22.9316 - sparse_categorical_accuracy: 0.0625\n",
            "Epoch 39/40\n",
            "32/32 [==============================] - 0s 391us/sample - loss: 27.7893 - sparse_categorical_accuracy: 0.1562\n",
            "Epoch 40/40\n",
            "32/32 [==============================] - 0s 349us/sample - loss: 21.7020 - sparse_categorical_accuracy: 0.1250\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fceb06e6ef0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2E5KoF3iqe6M",
        "colab_type": "text"
      },
      "source": [
        "**На всех данных:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHUoj6_q-qgC",
        "colab_type": "code",
        "outputId": "a21045e4-5199-4fa4-84fa-1dce03098351",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "adam = keras.optimizers.Adam()\n",
        "model.compile(optimizer=adam,\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=8, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/8\n",
            "52500/52500 [==============================] - 13s 239us/sample - loss: 2.8786 - sparse_categorical_accuracy: 0.1002 - val_loss: 2.3615 - val_sparse_categorical_accuracy: 0.1015\n",
            "Epoch 2/8\n",
            "52500/52500 [==============================] - 11s 219us/sample - loss: 2.3411 - sparse_categorical_accuracy: 0.0995 - val_loss: 2.3501 - val_sparse_categorical_accuracy: 0.1008\n",
            "Epoch 3/8\n",
            "52500/52500 [==============================] - 11s 219us/sample - loss: 2.3390 - sparse_categorical_accuracy: 0.0984 - val_loss: 2.3363 - val_sparse_categorical_accuracy: 0.1019\n",
            "Epoch 4/8\n",
            "52500/52500 [==============================] - 12s 221us/sample - loss: 2.3364 - sparse_categorical_accuracy: 0.1010 - val_loss: 2.3389 - val_sparse_categorical_accuracy: 0.1045\n",
            "Epoch 5/8\n",
            "52500/52500 [==============================] - 11s 219us/sample - loss: 2.3341 - sparse_categorical_accuracy: 0.1025 - val_loss: 2.3348 - val_sparse_categorical_accuracy: 0.1013\n",
            "Epoch 6/8\n",
            "52500/52500 [==============================] - 11s 218us/sample - loss: 2.3330 - sparse_categorical_accuracy: 0.1005 - val_loss: 2.3242 - val_sparse_categorical_accuracy: 0.1010\n",
            "Epoch 7/8\n",
            "52500/52500 [==============================] - 11s 218us/sample - loss: 2.3302 - sparse_categorical_accuracy: 0.1014 - val_loss: 2.3236 - val_sparse_categorical_accuracy: 0.1036\n",
            "Epoch 8/8\n",
            "52500/52500 [==============================] - 12s 219us/sample - loss: 2.3310 - sparse_categorical_accuracy: 0.1009 - val_loss: 2.3239 - val_sparse_categorical_accuracy: 0.1032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce1fa790b8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 268
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o34kVmutqhkF",
        "colab_type": "text"
      },
      "source": [
        "**LR range test:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QR4ne5h9mcEK",
        "colab_type": "code",
        "outputId": "04f5c910-e852-49b8-fca0-9e452f727e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 539
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "lr_finder = LRFinder(model)\n",
        "lr_finder.find(X_train, y_train, start_lr=0.0001, end_lr=100, batch_size=512, epochs=1)\n",
        "lr_finder.plot_loss(n_skip_beginning=1, n_skip_end=1, y_lim=(0, 25))\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples\n",
            "41472/52500 [======================>.......] - ETA: 1s - loss: 472.2243 - sparse_categorical_accuracy: 0.0996"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAs0AAAHoCAYAAACyxtKZAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n1sB/Aa4Wn5tAl821AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 864x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ph8SKcEEmoVV",
        "colab_type": "code",
        "outputId": "fe82f107-8eeb-43dc-c6f8-8ecdc390fc6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "model.compile(optimizer=keras.optimizers.SGD(1e-3),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['sparse_categorical_accuracy'])\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          batch_size=32, epochs=8, \n",
        "          validation_data=(X_test, y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 52500 samples, validate on 17500 samples\n",
            "Epoch 1/8\n",
            "52500/52500 [==============================] - 12s 230us/sample - loss: 3.4716 - sparse_categorical_accuracy: 0.1003 - val_loss: 3.8311 - val_sparse_categorical_accuracy: 0.0994\n",
            "Epoch 2/8\n",
            "52500/52500 [==============================] - 11s 211us/sample - loss: 3.2511 - sparse_categorical_accuracy: 0.0980 - val_loss: 4.5026 - val_sparse_categorical_accuracy: 0.0989\n",
            "Epoch 3/8\n",
            "52500/52500 [==============================] - 11s 210us/sample - loss: 3.2418 - sparse_categorical_accuracy: 0.0996 - val_loss: 3.2410 - val_sparse_categorical_accuracy: 0.0984\n",
            "Epoch 4/8\n",
            "52500/52500 [==============================] - 11s 210us/sample - loss: 3.1874 - sparse_categorical_accuracy: 0.1004 - val_loss: 3.8680 - val_sparse_categorical_accuracy: 0.0993\n",
            "Epoch 5/8\n",
            "52500/52500 [==============================] - 11s 210us/sample - loss: 3.2906 - sparse_categorical_accuracy: 0.1005 - val_loss: 2.6657 - val_sparse_categorical_accuracy: 0.0997\n",
            "Epoch 6/8\n",
            "52500/52500 [==============================] - 11s 211us/sample - loss: 3.1926 - sparse_categorical_accuracy: 0.0999 - val_loss: 3.3589 - val_sparse_categorical_accuracy: 0.0990\n",
            "Epoch 7/8\n",
            "52500/52500 [==============================] - 11s 211us/sample - loss: 3.2224 - sparse_categorical_accuracy: 0.1002 - val_loss: 2.9876 - val_sparse_categorical_accuracy: 0.0993\n",
            "Epoch 8/8\n",
            "52500/52500 [==============================] - 11s 214us/sample - loss: 3.2415 - sparse_categorical_accuracy: 0.0981 - val_loss: 3.1009 - val_sparse_categorical_accuracy: 0.0986\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fce245b1ac8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 278
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sgOnT2u3qkbo",
        "colab_type": "text"
      },
      "source": [
        "**Статистики:**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bn9Tcrf6Do3G",
        "colab_type": "code",
        "outputId": "2459cc04-a7d5-41b1-ce5c-718da2d77496",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 578
        }
      },
      "source": [
        "count_output_stats(model, X_train[:32])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Layer_name     Mean      Std     AbsMax\n",
            "input_29 33.669403 78.76575 255.0\n",
            "conv2d_140 4.231854 29.188667 210.1025\n",
            "tf_op_layer_split_28 4.231854 29.188667 210.1025\n",
            "batch_normalization_112 -0.060708497 1.01179 4.95125\n",
            "activation_163 0.28781343 0.6900325 2.853308\n",
            "conv2d_141 -0.15365316 0.9361949 5.795438\n",
            "batch_normalization_113 -0.1363029 0.9564958 5.326945\n",
            "activation_164 0.2682067 0.480782 4.5242367\n",
            "conv2d_142 0.050192434 0.49655452 4.2259264\n",
            "tf_op_layer_add_56 3.7044044 27.961082 196.4603\n",
            "batch_normalization_114 0.013626135 0.9481851 3.6829545\n",
            "activation_165 0.32152814 0.66628516 3.3332853\n",
            "conv2d_143 0.06382023 0.87668425 5.9434075\n",
            "batch_normalization_115 -0.0071410853 0.93496156 5.801188\n",
            "activation_166 0.32338476 0.619174 5.801188\n",
            "conv2d_144 -0.053391617 0.6353927 4.3104606\n",
            "tf_op_layer_add_57 4.756104 30.14578 209.5515\n",
            "tf_op_layer_concat_28 4.2302537 29.078714 209.5515\n",
            "flatten_28 4.2302537 29.078714 209.5515\n",
            "tf_op_layer_strided_slice_50 0.0699166 0.0 0.0699166\n",
            "tf_op_layer_strided_slice_51 0.26468927 0.020386474 0.3780875\n",
            "tf_op_layer_strided_slice_52 -3.9262862 5.151055 12.210673\n",
            "tf_op_layer_strided_slice_53 1.652812 1.7917815 4.1538424\n",
            "tf_op_layer_strided_slice_54 -0.23318125 0.674165 3.43379\n",
            "tf_op_layer_strided_slice_55 0.32106164 0.0 0.32106164\n",
            "tf_op_layer_strided_slice_56 -0.41378894 1.6264856 4.0039225\n",
            "tf_op_layer_strided_slice_57 -3.0676367 3.6280813 8.206318\n",
            "tf_op_layer_strided_slice_58 0.020501189 0.34784484 0.7425924\n",
            "tf_op_layer_strided_slice_59 0.08809745 0.042201024 0.25374326\n",
            "tf_op_layer_packed_5 -0.5223814 2.6715324 12.210673\n",
            "tf_op_layer_Reshape_5 -0.5223814 2.6715324 12.210673\n",
            "activation_167 0.1 0.07477676 0.8450352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml5niPHjsvGi",
        "colab_type": "text"
      },
      "source": [
        "В данной моделе видно, что она не может обучиться даже на маленьком батче, нужно исправлять модель."
      ]
    }
  ]
}